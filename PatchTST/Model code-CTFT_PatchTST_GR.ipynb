{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d82ca39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use of equipment: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score, mean_squared_error\n",
    "import pandas as pd\n",
    "import gc\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Use of equipment:\", device)\n",
    "\n",
    "# ------- PatchTST Configuration -------\n",
    "class Cfg:\n",
    "    pass\n",
    "\n",
    "configs = Cfg()\n",
    "configs.enc_in = 3        \n",
    "configs.seq_len = 100\n",
    "configs.pred_len = 1\n",
    "configs.e_layers = 3\n",
    "configs.n_heads = 4\n",
    "configs.d_model = 64 \n",
    "configs.d_ff = 128 \n",
    "configs.dropout = 0.4\n",
    "configs.fc_dropout = 0.4\n",
    "configs.head_dropout = 0.4\n",
    "configs.patch_len = 16\n",
    "configs.stride = 8\n",
    "configs.padding_patch = None\n",
    "configs.revin = True\n",
    "configs.affine = True\n",
    "configs.subtract_last = False\n",
    "configs.decomposition = True \n",
    "configs.kernel_size = 25\n",
    "configs.individual = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52b87f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Six-point coordinates\n",
    "coords = torch.tensor([\n",
    "    [532043.125, 3401273.750],\n",
    "    [532036.375, 3401250.250],\n",
    "    [532028.938, 3401220.750],\n",
    "    [532246.000, 3401357.500],\n",
    "    [532248.438, 3401325.500],\n",
    "    [532248.313, 3401293.000]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "##NOTE The water depth between adjacent locations should not differ significantly.\n",
    "neighbor_pairs = [(0,1), (1,2), (3,4), (4,5)]\n",
    "distances = torch.tensor([torch.norm(coords[i]-coords[j]).item() for i,j in neighbor_pairs], dtype=torch.float32)\n",
    "\n",
    "def continuity_loss(pred, y, beta=0.1, device=\"cpu\"):\n",
    "    mse = nn.MSELoss()(pred, y)\n",
    "    spatial_loss = 0.0\n",
    "    for k, (i,j) in enumerate(neighbor_pairs):\n",
    "        dij = distances[k].to(device)\n",
    "        spatial_loss += torch.mean(((pred[:,i]-pred[:,j])**2)/(dij**2))\n",
    "    return mse + beta*spatial_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cf85a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PatchTST import Model as PatchTSTModel   \n",
    "\n",
    "# ========= Image Residual Module =========\n",
    "class GraphResidualBlock(nn.Module):\n",
    "    def __init__(self, num_nodes, hidden_dim=32):\n",
    "        super().__init__()\n",
    "        self.num_nodes = num_nodes\n",
    "\n",
    "        # Trainable Adjacency Matrix  \n",
    "        self.A_param = nn.Parameter(torch.randn(num_nodes, num_nodes))\n",
    "\n",
    "        # Node Feature Transformation\n",
    "        self.fc1 = nn.Linear(1, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.dim() == 3:   \n",
    "            x = x.squeeze(1)  \n",
    "\n",
    "        # Normalised Adjacency Matrix\n",
    "        A = torch.softmax(self.A_param, dim=-1)  \n",
    "\n",
    "        h = x.unsqueeze(-1)         \n",
    "        h = self.fc1(h)             \n",
    "        h = torch.matmul(A, h)      \n",
    "        h = F.relu(h)\n",
    "        h = self.fc2(h).squeeze(-1)  \n",
    "\n",
    "        return x + h  # Residual connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62d3f80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GRN(nn.Module):\n",
    "    \"\"\" Gated Residual Network \"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim=None, dropout=0.1):\n",
    "        super().__init__()\n",
    "        output_dim = output_dim or input_dim\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.gate = nn.Linear(output_dim, output_dim)\n",
    "        self.norm = nn.LayerNorm(output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = F.gelu(self.fc1(x))\n",
    "        x = self.dropout(self.fc2(x))\n",
    "        gate = torch.sigmoid(self.gate(x))\n",
    "        x = gate * x + (1 - gate) * residual\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca8c9319",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\" Standard Transformer Position Encoding \"\"\"\n",
    "    def __init__(self, d_model, max_len=1000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2).float() * (-torch.log(torch.tensor(10000.0)) / d_model)\n",
    "        )\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)   \n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1), :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d02b2ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompactTFT(nn.Module):\n",
    "    \"\"\"\n",
    "    Enhanced TFT, designed to replace SimpleTFT\n",
    "    \"\"\"\n",
    "    def __init__(self, enc_in, d_model=64, n_heads=4, n_layers=2, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.input_proj = nn.Linear(enc_in, d_model)\n",
    "        self.pos_encoding = PositionalEncoding(d_model)\n",
    "\n",
    "        # Layer Stacking\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=n_heads,\n",
    "            dim_feedforward=d_model*2, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
    "\n",
    "        # Static fusion \n",
    "        self.static_fuse = GRN(d_model, d_model*2, d_model, dropout=dropout)\n",
    "\n",
    "        # Output layer normalisation\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x, static_emb=None):\n",
    "        x = self.input_proj(x)\n",
    "        x = self.pos_encoding(x)\n",
    "        x = self.encoder(x)\n",
    "\n",
    "        if static_emb is not None:\n",
    "            s = static_emb.unsqueeze(1).repeat(1, x.size(1), 1)\n",
    "            x = self.static_fuse(x + s)\n",
    "\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4f19182",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PatchTST import Model as PatchTSTModel   \n",
    "\n",
    "# ------------------------------\n",
    "# PatchTST Regression Tool (TFT at the forefront)\n",
    "# ------------------------------\n",
    "class PatchTSTRegressor(nn.Module):\n",
    "    def __init__(self, configs, c_out=6, gnn_hidden=32, d_model=64):\n",
    "        super().__init__()\n",
    "        self.pred_len = configs.pred_len\n",
    "        self.orig_c_in = configs.enc_in   \n",
    "        self.c_out = c_out\n",
    "\n",
    "        self.tft = CompactTFT(enc_in=self.orig_c_in, d_model=d_model, n_heads=4, n_layers=2, dropout=0.3)\n",
    "\n",
    "        import copy\n",
    "        new_configs = copy.deepcopy(configs)\n",
    "        new_configs.enc_in = d_model    \n",
    "        self.patch_model = PatchTSTModel(new_configs, max_seq_len=1024)\n",
    "\n",
    "        # Image Residual Block\n",
    "        self.graph_block = GraphResidualBlock(num_nodes=c_out, hidden_dim=gnn_hidden)\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(self.pred_len * d_model, 32),  # 注意这里用 d_model\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, c_out)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # First via TFT\n",
    "        x = self.tft(x)   \n",
    "\n",
    "        # PatchTST Output\n",
    "        out = self.patch_model(x)   \n",
    "        if out.shape[1] != self.pred_len:\n",
    "            out = out[:, -self.pred_len:, :]\n",
    "\n",
    "        yhat = self.head(out)  \n",
    "\n",
    "        # Image residual block refinement\n",
    "        yhat = self.graph_block(yhat)  \n",
    "\n",
    "        return yhat\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Initialise the model\n",
    "# ------------------------------\n",
    "model = PatchTSTRegressor(configs, c_out=6, gnn_hidden=16, d_model=32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68c33e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output shape: torch.Size([4, 6])\n"
     ]
    }
   ],
   "source": [
    "# forward test\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "B = 4\n",
    "seq_len = configs.seq_len   \n",
    "c_in = configs.enc_in        \n",
    "c_out = 6\n",
    "\n",
    "# Construct dummy input\n",
    "dummy_x_seq = torch.randn(B, seq_len, 2).to(device)       \n",
    "dummy_x_static = torch.randn(B, 1).to(device)             \n",
    "dummy_x = torch.cat([dummy_x_seq, dummy_x_static.unsqueeze(1).expand(-1, seq_len, -1)], dim=-1)   \n",
    "\n",
    "# Initialise the model\n",
    "model = PatchTSTRegressor(configs, c_out=c_out).to(device)\n",
    "model.eval()\n",
    "\n",
    "# Forward Testing\n",
    "with torch.no_grad():\n",
    "    out = model(dummy_x)\n",
    "    print(\"Model output shape:\", out.shape)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1197566",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Path\n",
    "data_dir = r\"D:\\0DATA\"\n",
    "\n",
    "# Loading data\n",
    "X_seq_train = np.load(f\"{data_dir}/X_seq_train.npy\")\n",
    "X_static_train = np.load(f\"{data_dir}/X_static_train.npy\")\n",
    "Y_train = np.load(f\"{data_dir}/Y_train.npy\")\n",
    "\n",
    "X_seq_test = np.load(f\"{data_dir}/X_seq_test.npy\")\n",
    "X_static_test = np.load(f\"{data_dir}/X_static_test.npy\")\n",
    "Y_test = np.load(f\"{data_dir}/Y_test.npy\")\n",
    "\n",
    "print(\"training set:\", X_seq_train.shape, X_static_train.shape, Y_train.shape)\n",
    "print(\"test set:\", X_seq_test.shape, X_static_test.shape, Y_test.shape)\n",
    "\n",
    "# ========== Min-Max Normalisation ==========\n",
    "def minmax_scale(train, test):\n",
    "    min_val = train.min(axis=0, keepdims=True)\n",
    "    max_val = train.max(axis=0, keepdims=True)\n",
    "    train_norm = (train - min_val) / (max_val - min_val + 1e-8)\n",
    "    test_norm = (test - min_val) / (max_val - min_val + 1e-8)\n",
    "    return train_norm, test_norm, min_val, max_val\n",
    "\n",
    "# Normalise the three types of data respectively\n",
    "X_seq_train, X_seq_test, X_seq_min, X_seq_max = minmax_scale(\n",
    "    X_seq_train.reshape(-1, X_seq_train.shape[-1]),\n",
    "    X_seq_test.reshape(-1, X_seq_test.shape[-1])\n",
    ")\n",
    "X_seq_train = X_seq_train.reshape(-1, configs.seq_len, 2)\n",
    "X_seq_test = X_seq_test.reshape(-1, configs.seq_len, 2)\n",
    "\n",
    "X_static_train, X_static_test, X_static_min, X_static_max = minmax_scale(X_static_train, X_static_test)\n",
    "Y_train, Y_test, Y_min, Y_max = minmax_scale(Y_train, Y_test)\n",
    "\n",
    "# numpy -> torch\n",
    "X_seq_train_t = torch.tensor(X_seq_train, dtype=torch.float32)\n",
    "X_static_train_t = torch.tensor(X_static_train, dtype=torch.float32)\n",
    "Y_train_t = torch.tensor(Y_train, dtype=torch.float32)\n",
    "\n",
    "X_seq_test_t = torch.tensor(X_seq_test, dtype=torch.float32)\n",
    "X_static_test_t = torch.tensor(X_static_test, dtype=torch.float32)\n",
    "Y_test_t = torch.tensor(Y_test, dtype=torch.float32)\n",
    "\n",
    "train_X = torch.cat([X_seq_train_t, X_static_train_t.unsqueeze(1).expand(-1, configs.seq_len, -1)], dim=-1)\n",
    "test_X = torch.cat([X_seq_test_t, X_static_test_t.unsqueeze(1).expand(-1, configs.seq_len, -1)], dim=-1)\n",
    "\n",
    "# TensorDataset + DataLoader\n",
    "BATCH_SIZE = 512\n",
    "train_dataset = TensorDataset(train_X, Y_train_t)\n",
    "val_dataset = TensorDataset(test_X, Y_test_t)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=10, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8, pin_memory=True)\n",
    "\n",
    "\n",
    "\n",
    "### Read the test set data for each operating condition ================================================\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# ===== Read the test sets for each operating condition =====\n",
    "case_dir = os.path.join(data_dir, \"test_cases\")\n",
    "test_data_per_case = {}\n",
    "\n",
    "# Locate the X_seq files for all cases\n",
    "case_files = glob.glob(os.path.join(case_dir, \"X_seq_case*.npy\"))\n",
    "\n",
    "for f in case_files:\n",
    "    fname = os.path.basename(f)   \n",
    "    case_id = int(fname.replace(\"X_seq_case\", \"\").replace(\".npy\", \"\"))\n",
    "\n",
    "    X_seq_case = np.load(os.path.join(case_dir, f\"X_seq_case{case_id}.npy\"))\n",
    "    X_static_case = np.load(os.path.join(case_dir, f\"X_static_case{case_id}.npy\"))\n",
    "    Y_case = np.load(os.path.join(case_dir, f\"Y_case{case_id}.npy\"))\n",
    "\n",
    "    test_data_per_case[case_id] = (X_seq_case, X_static_case, Y_case)\n",
    "\n",
    "print(f\"✅  {len(test_data_per_case)} test cases loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dce4a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, scaler, device):\n",
    "    model.train()\n",
    "    total_loss, total_rmse, total_mape, total_r2 = 0,0,0,0\n",
    "    n_samples = 0\n",
    "\n",
    "    for xb, yb in loader:\n",
    "        B = xb.size(0)\n",
    "        xb = xb.to(device, dtype=torch.float32)\n",
    "        yb = yb.to(device, dtype=torch.float32)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # Automatic Mixed Precision\n",
    "        with torch.amp.autocast(device_type='cuda', dtype=torch.float16):\n",
    "            out = model(xb)   # [B, 6]\n",
    "            loss = continuity_loss(out, yb, beta=0.1, device=device)\n",
    "\n",
    "        if torch.isnan(loss):\n",
    "            print(\"⚠️ Loss is NaN, skipping this batch.\")\n",
    "            continue\n",
    "\n",
    "        # Inverse Gradient Trimming + AMP\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)   \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  \n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # CPU Metric Calculation\n",
    "        y_np, out_np = yb.detach().cpu().numpy(), out.detach().cpu().numpy()\n",
    "\n",
    "        if np.isnan(out_np).any() or np.isnan(y_np).any():\n",
    "            print(\"⚠️ NaN detected in out_np or y_np, skipping this batch.\")\n",
    "            continue\n",
    "        if np.isinf(out_np).any():\n",
    "            print(\"⚠️ Inf detected in out_np, clipping.\")\n",
    "            out_np = np.nan_to_num(out_np, nan=0.0, posinf=1e6, neginf=-1e6)\n",
    "\n",
    "        rmse = np.sqrt(mean_squared_error(y_np, out_np))\n",
    "        #mape = mean_absolute_percentage_error(y_np, out_np)\n",
    "        r2 = r2_score(y_np, out_np)\n",
    "\n",
    "        total_loss += loss.item() * B\n",
    "        total_rmse += rmse * B\n",
    "        #total_mape += mape * B\n",
    "        total_r2 += r2 * B\n",
    "        n_samples += B\n",
    "\n",
    "    return total_loss/n_samples, total_rmse/n_samples, 0, total_r2/n_samples\n",
    "\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    total_loss, total_rmse, total_mape, total_max, total_r2 = 0,0,0,0,0\n",
    "    n_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            B = xb.size(0)\n",
    "            xb = xb.to(device, dtype=torch.float32)\n",
    "            yb = yb.to(device, dtype=torch.float32)\n",
    "\n",
    "            out = model(xb)\n",
    "            loss = continuity_loss(out, yb, beta=0.1, device=device)\n",
    "\n",
    "            y_np, out_np = yb.detach().cpu().numpy(), out.detach().cpu().numpy()\n",
    "            rmse = np.sqrt(mean_squared_error(y_np, out_np))\n",
    "            mape = mean_absolute_percentage_error(y_np, out_np)\n",
    "            max_err = np.max(np.abs(y_np - out_np))\n",
    "            r2 = r2_score(y_np, out_np)\n",
    "\n",
    "            total_loss += loss.item() * B\n",
    "            total_rmse += rmse * B\n",
    "            total_mape += mape * B\n",
    "            total_max += max_err * B\n",
    "            total_r2 += r2 * B\n",
    "            n_samples += B\n",
    "\n",
    "    return total_loss/n_samples, total_rmse/n_samples, total_mape/n_samples, total_max/n_samples, total_r2/n_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8429a1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PatchTSTRegressor(\n",
      "  (tft): CompactTFT(\n",
      "    (input_proj): Linear(in_features=3, out_features=64, bias=True)\n",
      "    (pos_encoding): PositionalEncoding()\n",
      "    (encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0-1): 2 x TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.3, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.3, inplace=False)\n",
      "          (dropout2): Dropout(p=0.3, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (static_fuse): GRN(\n",
      "      (fc1): Linear(in_features=64, out_features=128, bias=True)\n",
      "      (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (gate): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.3, inplace=False)\n",
      "    )\n",
      "    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (patch_model): Model(\n",
      "    (decomp_module): series_decomp(\n",
      "      (moving_avg): moving_avg(\n",
      "        (avg): AvgPool1d(kernel_size=(25,), stride=(1,), padding=(0,))\n",
      "      )\n",
      "    )\n",
      "    (model_trend): PatchTST_backbone(\n",
      "      (revin_layer): RevIN()\n",
      "      (backbone): TSTiEncoder(\n",
      "        (W_P): Linear(in_features=16, out_features=64, bias=True)\n",
      "        (dropout): Dropout(p=0.4, inplace=False)\n",
      "        (encoder): TSTEncoder(\n",
      "          (layers): ModuleList(\n",
      "            (0-2): 3 x TSTEncoderLayer(\n",
      "              (self_attn): _MultiheadAttention(\n",
      "                (W_Q): Linear(in_features=64, out_features=64, bias=True)\n",
      "                (W_K): Linear(in_features=64, out_features=64, bias=True)\n",
      "                (W_V): Linear(in_features=64, out_features=64, bias=True)\n",
      "                (sdp_attn): _ScaledDotProductAttention(\n",
      "                  (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (to_out): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "                  (1): Dropout(p=0.4, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (dropout_attn): Dropout(p=0.4, inplace=False)\n",
      "              (norm_attn): Sequential(\n",
      "                (0): Transpose()\n",
      "                (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Transpose()\n",
      "              )\n",
      "              (ff): Sequential(\n",
      "                (0): Linear(in_features=64, out_features=128, bias=True)\n",
      "                (1): GELU(approximate='none')\n",
      "                (2): Dropout(p=0.4, inplace=False)\n",
      "                (3): Linear(in_features=128, out_features=64, bias=True)\n",
      "              )\n",
      "              (dropout_ffn): Dropout(p=0.4, inplace=False)\n",
      "              (norm_ffn): Sequential(\n",
      "                (0): Transpose()\n",
      "                (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Transpose()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (head): Flatten_Head(\n",
      "        (flatten): Flatten(start_dim=-2, end_dim=-1)\n",
      "        (linear): Linear(in_features=704, out_features=1, bias=True)\n",
      "        (dropout): Dropout(p=0.4, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (model_res): PatchTST_backbone(\n",
      "      (revin_layer): RevIN()\n",
      "      (backbone): TSTiEncoder(\n",
      "        (W_P): Linear(in_features=16, out_features=64, bias=True)\n",
      "        (dropout): Dropout(p=0.4, inplace=False)\n",
      "        (encoder): TSTEncoder(\n",
      "          (layers): ModuleList(\n",
      "            (0-2): 3 x TSTEncoderLayer(\n",
      "              (self_attn): _MultiheadAttention(\n",
      "                (W_Q): Linear(in_features=64, out_features=64, bias=True)\n",
      "                (W_K): Linear(in_features=64, out_features=64, bias=True)\n",
      "                (W_V): Linear(in_features=64, out_features=64, bias=True)\n",
      "                (sdp_attn): _ScaledDotProductAttention(\n",
      "                  (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (to_out): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "                  (1): Dropout(p=0.4, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (dropout_attn): Dropout(p=0.4, inplace=False)\n",
      "              (norm_attn): Sequential(\n",
      "                (0): Transpose()\n",
      "                (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Transpose()\n",
      "              )\n",
      "              (ff): Sequential(\n",
      "                (0): Linear(in_features=64, out_features=128, bias=True)\n",
      "                (1): GELU(approximate='none')\n",
      "                (2): Dropout(p=0.4, inplace=False)\n",
      "                (3): Linear(in_features=128, out_features=64, bias=True)\n",
      "              )\n",
      "              (dropout_ffn): Dropout(p=0.4, inplace=False)\n",
      "              (norm_ffn): Sequential(\n",
      "                (0): Transpose()\n",
      "                (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Transpose()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (head): Flatten_Head(\n",
      "        (flatten): Flatten(start_dim=-2, end_dim=-1)\n",
      "        (linear): Linear(in_features=704, out_features=1, bias=True)\n",
      "        (dropout): Dropout(p=0.4, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (graph_block): GraphResidualBlock(\n",
      "    (fc1): Linear(in_features=1, out_features=32, bias=True)\n",
      "    (fc2): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      "  (head): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=32, out_features=6, bias=True)\n",
      "  )\n",
      ")\n",
      "=============================================================================================================================\n",
      "Layer (type:depth-idx)                                                      Output Shape              Param #\n",
      "=============================================================================================================================\n",
      "PatchTSTRegressor                                                           [2, 6]                    --\n",
      "├─CompactTFT: 1-1                                                           [2, 100, 64]              20,864\n",
      "│    └─Linear: 2-1                                                          [2, 100, 64]              256\n",
      "│    └─PositionalEncoding: 2-2                                              [2, 100, 64]              --\n",
      "│    └─TransformerEncoder: 2-3                                              [2, 100, 64]              --\n",
      "│    │    └─ModuleList: 3-1                                                 --                        66,944\n",
      "│    └─LayerNorm: 2-4                                                       [2, 100, 64]              128\n",
      "├─Model: 1-2                                                                [2, 1, 64]                --\n",
      "│    └─series_decomp: 2-5                                                   [2, 100, 64]              --\n",
      "│    │    └─moving_avg: 3-2                                                 [2, 100, 64]              --\n",
      "│    └─PatchTST_backbone: 2-6                                               [2, 64, 1]                --\n",
      "│    │    └─RevIN: 3-3                                                      [2, 100, 64]              128\n",
      "│    │    └─TSTiEncoder: 3-4                                                [2, 64, 64, 11]           102,211\n",
      "│    │    └─Flatten_Head: 3-5                                               [2, 64, 1]                705\n",
      "│    │    └─RevIN: 3-6                                                      [2, 1, 64]                (recursive)\n",
      "│    └─PatchTST_backbone: 2-7                                               [2, 64, 1]                --\n",
      "│    │    └─RevIN: 3-7                                                      [2, 100, 64]              128\n",
      "│    │    └─TSTiEncoder: 3-8                                                [2, 64, 64, 11]           102,211\n",
      "│    │    └─Flatten_Head: 3-9                                               [2, 64, 1]                705\n",
      "│    │    └─RevIN: 3-10                                                     [2, 1, 64]                (recursive)\n",
      "├─Sequential: 1-3                                                           [2, 6]                    --\n",
      "│    └─Flatten: 2-8                                                         [2, 64]                   --\n",
      "│    └─Linear: 2-9                                                          [2, 32]                   2,080\n",
      "│    └─ReLU: 2-10                                                           [2, 32]                   --\n",
      "│    └─Linear: 2-11                                                         [2, 6]                    198\n",
      "├─GraphResidualBlock: 1-4                                                   [2, 6]                    36\n",
      "│    └─Linear: 2-12                                                         [2, 6, 32]                64\n",
      "│    └─Linear: 2-13                                                         [2, 6, 1]                 33\n",
      "=============================================================================================================================\n",
      "Total params: 296,691\n",
      "Trainable params: 296,685\n",
      "Non-trainable params: 6\n",
      "Total mult-adds (Units.MEGABYTES): 25.84\n",
      "=============================================================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 41.81\n",
      "Params size (MB): 0.96\n",
      "Estimated Total Size (MB): 42.78\n",
      "=============================================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=============================================================================================================================\n",
       "Layer (type:depth-idx)                                                      Output Shape              Param #\n",
       "=============================================================================================================================\n",
       "PatchTSTRegressor                                                           [2, 6]                    --\n",
       "├─CompactTFT: 1-1                                                           [2, 100, 64]              20,864\n",
       "│    └─Linear: 2-1                                                          [2, 100, 64]              256\n",
       "│    └─PositionalEncoding: 2-2                                              [2, 100, 64]              --\n",
       "│    └─TransformerEncoder: 2-3                                              [2, 100, 64]              --\n",
       "│    │    └─ModuleList: 3-1                                                 --                        66,944\n",
       "│    └─LayerNorm: 2-4                                                       [2, 100, 64]              128\n",
       "├─Model: 1-2                                                                [2, 1, 64]                --\n",
       "│    └─series_decomp: 2-5                                                   [2, 100, 64]              --\n",
       "│    │    └─moving_avg: 3-2                                                 [2, 100, 64]              --\n",
       "│    └─PatchTST_backbone: 2-6                                               [2, 64, 1]                --\n",
       "│    │    └─RevIN: 3-3                                                      [2, 100, 64]              128\n",
       "│    │    └─TSTiEncoder: 3-4                                                [2, 64, 64, 11]           102,211\n",
       "│    │    └─Flatten_Head: 3-5                                               [2, 64, 1]                705\n",
       "│    │    └─RevIN: 3-6                                                      [2, 1, 64]                (recursive)\n",
       "│    └─PatchTST_backbone: 2-7                                               [2, 64, 1]                --\n",
       "│    │    └─RevIN: 3-7                                                      [2, 100, 64]              128\n",
       "│    │    └─TSTiEncoder: 3-8                                                [2, 64, 64, 11]           102,211\n",
       "│    │    └─Flatten_Head: 3-9                                               [2, 64, 1]                705\n",
       "│    │    └─RevIN: 3-10                                                     [2, 1, 64]                (recursive)\n",
       "├─Sequential: 1-3                                                           [2, 6]                    --\n",
       "│    └─Flatten: 2-8                                                         [2, 64]                   --\n",
       "│    └─Linear: 2-9                                                          [2, 32]                   2,080\n",
       "│    └─ReLU: 2-10                                                           [2, 32]                   --\n",
       "│    └─Linear: 2-11                                                         [2, 6]                    198\n",
       "├─GraphResidualBlock: 1-4                                                   [2, 6]                    36\n",
       "│    └─Linear: 2-12                                                         [2, 6, 32]                64\n",
       "│    └─Linear: 2-13                                                         [2, 6, 1]                 33\n",
       "=============================================================================================================================\n",
       "Total params: 296,691\n",
       "Trainable params: 296,685\n",
       "Non-trainable params: 6\n",
       "Total mult-adds (Units.MEGABYTES): 25.84\n",
       "=============================================================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 41.81\n",
       "Params size (MB): 0.96\n",
       "Estimated Total Size (MB): 42.78\n",
       "============================================================================================================================="
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model)\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "summary(\n",
    "    model,\n",
    "    input_data=torch.randn(2, configs.seq_len, configs.enc_in).to(device),  # 对应 PatchTSTRegressor.forward\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272915af",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5000\n",
    "best_val_loss = float('inf')\n",
    "best_val_me = float(\"inf\")\n",
    "\n",
    "train_loss_list, val_loss_list = [], []\n",
    "\n",
    "save_path = r\"D:\\0DATA\"\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "excel_file = os.path.join(save_path, \"train_val_loss_1008.xlsx\")\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
    "scaler = torch.amp.GradScaler()\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    train_loss, train_rmse, train_mape, train_r2 = train_one_epoch(model, train_loader, optimizer, scaler, device)\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    val_loss, val_rmse, val_mape, val_max, val_r2 = evaluate(model, val_loader, device)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model, os.path.join(save_path, f\"best_val_mse_1013_test.pth\"))\n",
    "\n",
    "    # --- Model with the smallest maximum error ---\n",
    "    if val_max < best_val_me:\n",
    "        best_val_me = val_max\n",
    "        torch.save(model, os.path.join(save_path, f\"best_val_max_1013_test.pth\"))\n",
    "\n",
    "\n",
    "    # --- Output indicators ---\n",
    "    print(\n",
    "        f\"Epoch {epoch:02d}/{epochs} | \"\n",
    "        f\"Train Loss: {train_loss:.6f} , Val Loss: {val_loss:.6f} | \"\n",
    "        f\"Train RMSE: {train_rmse:.6f} , Train R2: {train_r2:.6f} | \"\n",
    "        f\"Val RMSE: {val_rmse:.6f} , Val MAPE: {val_mape:.6f} , Val Max_Err: {val_max:.6f}\"\n",
    "    )\n",
    "\n",
    "    train_loss_list.append(train_loss)\n",
    "    val_loss_list.append(val_loss)\n",
    "\n",
    "df_loss = pd.DataFrame({\n",
    "    \"Train Loss\": train_loss_list,\n",
    "    \"Validation Loss\": val_loss_list\n",
    "})\n",
    "df_loss.to_excel(excel_file, index_label=\"Epoch\")\n",
    "\n",
    "print(\"✅ Training complete, best validation set loss:\", best_val_loss)\n",
    "print(f\"Training/Validation Loss saved to: {excel_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
