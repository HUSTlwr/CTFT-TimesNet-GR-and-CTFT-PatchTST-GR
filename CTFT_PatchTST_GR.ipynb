{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fa50a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcfbd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def process_excel(filepath, seq_len=100, step=1, verbose=False):\n",
    "    df = pd.read_excel(filepath, header=None)\n",
    "    \n",
    "    if df.shape[0] <= 1 or df.shape[1] <= 1:\n",
    "        raise ValueError(f\"文件 {filepath} 行/列过少: {df.shape}\")\n",
    "    \n",
    "    df = df.iloc[1:, 1:].reset_index(drop=True)\n",
    "    \n",
    "    depth_col_indices = [3 + 4*i + 1 for i in range(6)]\n",
    "    max_needed_col = max(depth_col_indices)\n",
    "    if max_needed_col >= df.shape[1]:\n",
    "        raise ValueError(\n",
    "            f\"文件 {filepath} 列数不足，期望至少 {max_needed_col+1} 列（当前 {df.shape[1]} 列）。\"\n",
    "            \" 请确认 Excel 列的排列是否与预期一致。\"\n",
    "        )\n",
    "\n",
    "    downstream_level = df.iloc[0, 0]\n",
    "    try:\n",
    "        downstream_level = float(downstream_level)\n",
    "    except Exception:\n",
    "        downstream_level = np.nan\n",
    "\n",
    "    flows = df.iloc[:, 1:3].astype(float).values  # shape (T, 2)\n",
    "\n",
    "    depths = df.iloc[:, depth_col_indices].astype(float).values  # shape (T, 6)\n",
    "\n",
    "    T = len(df)\n",
    "    X_seq_list = []\n",
    "    X_static_list = []\n",
    "    Y_list = []\n",
    "\n",
    "    start_idx = seq_len * step\n",
    "    if T <= start_idx:\n",
    "        if verbose:\n",
    "            print(f\"Warning: 文件 {filepath} 时间步 (T={T}) <= seq_len*step ({start_idx})，没有样本。\")\n",
    "        return (np.empty((0, seq_len, flows.shape[1]), dtype=np.float32),\n",
    "                np.empty((0, 1), dtype=np.float32),\n",
    "                np.empty((0, depths.shape[1]), dtype=np.float32))\n",
    "\n",
    "    for t in range(start_idx, T, step):\n",
    "        seq_input = flows[t - seq_len*step : t : step, :]   \n",
    "        if seq_input.shape[0] != seq_len: \n",
    "            if verbose:\n",
    "                print(f\"跳过 t={t}：序列长度 {seq_input.shape[0]} != seq_len {seq_len}\")\n",
    "            continue\n",
    "\n",
    "        # 静态输入：仅下游边界水位（定值）\n",
    "        static_input = np.array([downstream_level], dtype=np.float32)  # shape (1,)\n",
    "\n",
    "        # 输出：当前时间步的 6 点深度\n",
    "        y = depths[t]  # shape (6,)\n",
    "\n",
    "        # 若任一处含 NaN，跳过该样本（可选，也可以改为插值/填充）\n",
    "        if np.isnan(seq_input).any() or np.isnan(static_input).any() or np.isnan(y).any():\n",
    "            if verbose:\n",
    "                print(f\"跳过 t={t}：发现 NaN (seq_input 或 static_input 或 y).\")\n",
    "            continue\n",
    "\n",
    "        X_seq_list.append(seq_input.astype(np.float32))\n",
    "        X_static_list.append(static_input.astype(np.float32))\n",
    "        Y_list.append(y.astype(np.float32))\n",
    "\n",
    "    if len(X_seq_list) == 0:\n",
    "        # 无有效样本，返回空数组（保持维度）\n",
    "        return (np.empty((0, seq_len, flows.shape[1]), dtype=np.float32),\n",
    "                np.empty((0, 1), dtype=np.float32),\n",
    "                np.empty((0, depths.shape[1]), dtype=np.float32))\n",
    "\n",
    "    X_seq_arr = np.stack(X_seq_list, axis=0)     # (N, seq_len, 2)\n",
    "    X_static_arr = np.stack(X_static_list, axis=0)  # (N, 1)\n",
    "    Y_arr = np.stack(Y_list, axis=0)             # (N, 6)\n",
    "\n",
    "    return X_seq_arr, X_static_arr, Y_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1681845c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excel 文件目录\n",
    "data_dir = r\"D:\\0DATA\"   # 修改为你的存放路径\n",
    "file_pathes = []\n",
    "for i in range(1, 49):  # 1 ~ 48\n",
    "    file_path = os.path.join(data_dir, f\"case{i}.xlsx\")\n",
    "    file_pathes.append((i, file_path))\n",
    "\n",
    "# 手动指定测试集工况索引（这里举例选择13个，可以自己改）\n",
    "test_indices = [22, 24, 3, 6, 15, 31, 34, 18, 38, 39, 42, 43, 48] \n",
    "train_indices = [i for i in range(1, (len(file_pathes) + 1)) if i not in test_indices]\n",
    "\n",
    "print(\"训练集工况数:\", len(train_indices))\n",
    "print(train_indices)\n",
    "print(\"测试集工况数:\", len(test_indices))\n",
    "print(test_indices)\n",
    "\n",
    "print(type(file_pathes))\n",
    "for path in file_pathes:\n",
    "    print(path[0], path[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a7bec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "X_seq_train, X_static_train, Y_train = [], [], []\n",
    "X_seq_test, X_static_test, Y_test = [], [], []\n",
    "\n",
    "test_data_per_case = {}  # 保存每个工况的测试数据\n",
    "\n",
    "for idx, filepath in file_pathes:\n",
    "    # filepath = os.path.join(data_dir, fname)\n",
    "    print(f\"处理工况 {idx}: {filepath}\")\n",
    "\n",
    "    X_seq, X_static, Y = process_excel(filepath)\n",
    "    if(torch.isnan(torch.from_numpy(X_seq)).any()):\n",
    "        print(idx, \"  |  \", filepath)\n",
    "\n",
    "    if idx in train_indices:\n",
    "        X_seq_train.append(X_seq)\n",
    "        X_static_train.append(X_static)\n",
    "        Y_train.append(Y)\n",
    "    else:\n",
    "        X_seq_test.append(X_seq)\n",
    "        X_static_test.append(X_static)\n",
    "        Y_test.append(Y)\n",
    "        test_data_per_case[idx] = (X_seq, X_static, Y)\n",
    "\n",
    "# 拼接训练、测试数据\n",
    "X_seq_train = np.concatenate(X_seq_train, axis=0)\n",
    "X_static_train = np.concatenate(X_static_train, axis=0)\n",
    "Y_train = np.concatenate(Y_train, axis=0)\n",
    "\n",
    "X_seq_test = np.concatenate(X_seq_test, axis=0)\n",
    "X_static_test = np.concatenate(X_static_test, axis=0)\n",
    "Y_test = np.concatenate(Y_test, axis=0)\n",
    "\n",
    "print(\"训练集输入 shape:\", X_seq_train.shape, X_static_train.shape)\n",
    "print(\"测试集输入 shape:\", X_seq_test.shape, X_static_test.shape)\n",
    "print(\"训练集输出 shape:\", Y_train.shape)\n",
    "print(\"测试集输出 shape:\", Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd472a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 数据保存完成！\n"
     ]
    }
   ],
   "source": [
    "output_dir = r\"D:\\0DATA\\DataSet\\processed_data\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 合并后的训练/测试集\n",
    "np.save(os.path.join(output_dir, \"X_seq_train.npy\"), X_seq_train)\n",
    "np.save(os.path.join(output_dir, \"X_static_train.npy\"), X_static_train)\n",
    "np.save(os.path.join(output_dir, \"Y_train.npy\"), Y_train)\n",
    "\n",
    "np.save(os.path.join(output_dir, \"X_seq_test.npy\"), X_seq_test)\n",
    "np.save(os.path.join(output_dir, \"X_static_test.npy\"), X_static_test)\n",
    "np.save(os.path.join(output_dir, \"Y_test.npy\"), Y_test)\n",
    "\n",
    "# 测试集按工况单独保存\n",
    "case_dir = os.path.join(output_dir, \"test_cases\")\n",
    "os.makedirs(case_dir, exist_ok=True)\n",
    "\n",
    "for idx, (X_seq, X_static, Y) in test_data_per_case.items():\n",
    "    np.save(os.path.join(case_dir, f\"X_seq_case{idx}.npy\"), X_seq)\n",
    "    np.save(os.path.join(case_dir, f\"X_static_case{idx}.npy\"), X_static)\n",
    "    np.save(os.path.join(case_dir, f\"Y_case{idx}.npy\"), Y)\n",
    "\n",
    "print(\"✅ 数据保存完成！\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfd31ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d82ca39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score, mean_squared_error\n",
    "import pandas as pd\n",
    "import gc\n",
    "\n",
    "# 设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"使用设备:\", device)\n",
    "\n",
    "# ------- PatchTST 配置 -------\n",
    "class Cfg:\n",
    "    pass\n",
    "\n",
    "configs = Cfg()\n",
    "configs.enc_in = 3         # 2 原始 + 1 静态特征\n",
    "configs.seq_len = 100\n",
    "configs.pred_len = 1\n",
    "configs.e_layers = 3\n",
    "configs.n_heads = 4\n",
    "configs.d_model = 64 #64\n",
    "configs.d_ff = 128 # 128\n",
    "configs.dropout = 0.4\n",
    "configs.fc_dropout = 0.4\n",
    "configs.head_dropout = 0.4\n",
    "configs.patch_len = 16\n",
    "configs.stride = 8\n",
    "configs.padding_patch = None\n",
    "configs.revin = True\n",
    "configs.affine = True\n",
    "configs.subtract_last = False\n",
    "configs.decomposition = True #False\n",
    "configs.kernel_size = 25\n",
    "configs.individual = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b87f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 损失函数\n",
    "# 六个点坐标\n",
    "coords = torch.tensor([\n",
    "    [532043.125, 3401273.750],\n",
    "    [532036.375, 3401250.250],\n",
    "    [532028.938, 3401220.750],\n",
    "    [532246.000, 3401357.500],\n",
    "    [532248.438, 3401325.500],\n",
    "    [532248.313, 3401293.000]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "##NOTE 相邻位置之间的水深不应该相差太大\n",
    "neighbor_pairs = [(0,1), (1,2), (3,4), (4,5)]\n",
    "distances = torch.tensor([torch.norm(coords[i]-coords[j]).item() for i,j in neighbor_pairs], dtype=torch.float32)\n",
    "\n",
    "def continuity_loss(pred, y, beta=0.1, device=\"cpu\"):\n",
    "    mse = nn.MSELoss()(pred, y)\n",
    "    spatial_loss = 0.0\n",
    "    for k, (i,j) in enumerate(neighbor_pairs):\n",
    "        dij = distances[k].to(device)\n",
    "        spatial_loss += torch.mean(((pred[:,i]-pred[:,j])**2)/(dij**2))\n",
    "    return mse + beta*spatial_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf85a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PatchTST import Model as PatchTSTModel   \n",
    "\n",
    "# ========= 图残差模块 =========\n",
    "class GraphResidualBlock(nn.Module):\n",
    "    def __init__(self, num_nodes, hidden_dim=32):\n",
    "        \"\"\"\n",
    "        num_nodes: 节点数 (例如6)\n",
    "        hidden_dim: 中间隐藏维度\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_nodes = num_nodes\n",
    "\n",
    "        # 可学习邻接矩阵 [N, N]\n",
    "        self.A_param = nn.Parameter(torch.randn(num_nodes, num_nodes))\n",
    "\n",
    "        # 节点特征变换\n",
    "        self.fc1 = nn.Linear(1, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: [B, N] 或 [B, 1, N]\n",
    "        \"\"\"\n",
    "        if x.dim() == 3:  # [B, 1, N]\n",
    "            x = x.squeeze(1)  # [B, N]\n",
    "\n",
    "        A = torch.softmax(self.A_param, dim=-1)  # [N, N]\n",
    "\n",
    "        h = x.unsqueeze(-1)         # [B, N, 1]\n",
    "        h = self.fc1(h)             # [B, N, H]\n",
    "        h = torch.matmul(A, h)      # [B, N, H]\n",
    "        h = F.relu(h)\n",
    "        h = self.fc2(h).squeeze(-1) # [B, N]\n",
    "\n",
    "        return x + h  # 残差连接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d3f80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# --- 子模块 ---\n",
    "class GRN(nn.Module):\n",
    "    \"\"\"Gated Residual Network\"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim=None, dropout=0.1):\n",
    "        super().__init__()\n",
    "        output_dim = output_dim or input_dim\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.gate = nn.Linear(output_dim, output_dim)\n",
    "        self.norm = nn.LayerNorm(output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = F.gelu(self.fc1(x))\n",
    "        x = self.dropout(self.fc2(x))\n",
    "        gate = torch.sigmoid(self.gate(x))\n",
    "        x = gate * x + (1 - gate) * residual\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8c9319",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=1000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2).float() * (-torch.log(torch.tensor(10000.0)) / d_model)\n",
    "        )\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)  # [1, max_len, d_model]\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1), :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02b2ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CTFT ---\n",
    "class CompactTFT(nn.Module):\n",
    "    def __init__(self, enc_in, d_model=64, n_heads=4, n_layers=2, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.input_proj = nn.Linear(enc_in, d_model)\n",
    "        self.pos_encoding = PositionalEncoding(d_model)\n",
    "\n",
    "        # 层堆叠\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=n_heads,\n",
    "            dim_feedforward=d_model*2, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
    "        self.static_fuse = GRN(d_model, d_model*2, d_model, dropout=dropout)\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x, static_emb=None):\n",
    "        x = self.input_proj(x)\n",
    "        x = self.pos_encoding(x)\n",
    "        x = self.encoder(x)\n",
    "\n",
    "        if static_emb is not None:\n",
    "            s = static_emb.unsqueeze(1).repeat(1, x.size(1), 1)\n",
    "            x = self.static_fuse(x + s)\n",
    "\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f19182",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PatchTST import Model as PatchTSTModel   # 根据实际路径\n",
    "\n",
    "# ------------------------------\n",
    "# PatchTST 回归器 (TFT 在前)\n",
    "# ------------------------------\n",
    "class PatchTSTRegressor(nn.Module):\n",
    "    def __init__(self, configs, c_out=6, gnn_hidden=32, d_model=64):\n",
    "        super().__init__()\n",
    "        self.pred_len = configs.pred_len\n",
    "        self.orig_c_in = configs.enc_in    \n",
    "        self.c_out = c_out\n",
    "        \n",
    "        self.tft = CompactTFT(enc_in=self.orig_c_in, d_model=d_model, n_heads=4, n_layers=2, dropout=0.3)\n",
    "\n",
    "        import copy\n",
    "        new_configs = copy.deepcopy(configs)\n",
    "        new_configs.enc_in = d_model    \n",
    "        self.patch_model = PatchTSTModel(new_configs, max_seq_len=1024)\n",
    "        self.graph_block = GraphResidualBlock(num_nodes=c_out, hidden_dim=gnn_hidden)\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(self.pred_len * d_model, 32),   \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, c_out)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.tft(x)  # [B, seq_len, d_model]\n",
    "        out = self.patch_model(x)  # [B, pred_len, d_model]\n",
    "        if out.shape[1] != self.pred_len:\n",
    "            out = out[:, -self.pred_len:, :]\n",
    "\n",
    "        yhat = self.head(out)  # [B, c_out]\n",
    "        # 图残差块 refine\n",
    "        yhat = self.graph_block(yhat)  # [B, c_out]\n",
    "\n",
    "        return yhat\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# 初始化模型\n",
    "# ------------------------------\n",
    "model = PatchTSTRegressor(configs, c_out=6, gnn_hidden=16, d_model=32).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c33e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型输出 shape: torch.Size([4, 6])\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "B = 4\n",
    "seq_len = configs.seq_len   \n",
    "c_in = configs.enc_in      \n",
    "c_out = 6\n",
    "\n",
    "dummy_x_seq = torch.randn(B, seq_len, 2).to(device)       \n",
    "dummy_x_static = torch.randn(B, 1).to(device)             \n",
    "dummy_x = torch.cat([dummy_x_seq, dummy_x_static.unsqueeze(1).expand(-1, seq_len, -1)], dim=-1)  \n",
    "\n",
    "model = PatchTSTRegressor(configs, c_out=c_out).to(device)\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = model(dummy_x)\n",
    "    print(\"模型输出 shape:\", out.shape)  # 期望 [B, c_out]，例如 [4, 6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1197566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集: (55085, 100, 2) (55085, 1) (55085, 6)\n",
      "测试集: (20793, 100, 2) (20793, 1) (20793, 6)\n",
      "✅ 已加载 13 个工况测试集\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "data_dir = r\"D:\\0DATA\\DataSet\\processed_data\"\n",
    "\n",
    "X_seq_train = np.load(f\"{data_dir}/X_seq_train.npy\")\n",
    "X_static_train = np.load(f\"{data_dir}/X_static_train.npy\")\n",
    "Y_train = np.load(f\"{data_dir}/Y_train.npy\")\n",
    "\n",
    "X_seq_test = np.load(f\"{data_dir}/X_seq_test.npy\")\n",
    "X_static_test = np.load(f\"{data_dir}/X_static_test.npy\")\n",
    "Y_test = np.load(f\"{data_dir}/Y_test.npy\")\n",
    "\n",
    "print(\"训练集:\", X_seq_train.shape, X_static_train.shape, Y_train.shape)\n",
    "print(\"测试集:\", X_seq_test.shape, X_static_test.shape, Y_test.shape)\n",
    "\n",
    "# ========== Min-Max 归一化 ==========\n",
    "def minmax_scale(train, test):\n",
    "    min_val = train.min(axis=0, keepdims=True)\n",
    "    max_val = train.max(axis=0, keepdims=True)\n",
    "    train_norm = (train - min_val) / (max_val - min_val + 1e-8)\n",
    "    test_norm = (test - min_val) / (max_val - min_val + 1e-8)\n",
    "    return train_norm, test_norm, min_val, max_val\n",
    "\n",
    "# 对三类数据分别做归一化\n",
    "X_seq_train, X_seq_test, X_seq_min, X_seq_max = minmax_scale(\n",
    "    X_seq_train.reshape(-1, X_seq_train.shape[-1]),\n",
    "    X_seq_test.reshape(-1, X_seq_test.shape[-1])\n",
    ")\n",
    "X_seq_train = X_seq_train.reshape(-1, configs.seq_len, 2)\n",
    "X_seq_test = X_seq_test.reshape(-1, configs.seq_len, 2)\n",
    "\n",
    "X_static_train, X_static_test, X_static_min, X_static_max = minmax_scale(X_static_train, X_static_test)\n",
    "Y_train, Y_test, Y_min, Y_max = minmax_scale(Y_train, Y_test)\n",
    "\n",
    "# numpy -> torch\n",
    "X_seq_train_t = torch.tensor(X_seq_train, dtype=torch.float32)\n",
    "X_static_train_t = torch.tensor(X_static_train, dtype=torch.float32)\n",
    "Y_train_t = torch.tensor(Y_train, dtype=torch.float32)\n",
    "\n",
    "X_seq_test_t = torch.tensor(X_seq_test, dtype=torch.float32)\n",
    "X_static_test_t = torch.tensor(X_static_test, dtype=torch.float32)\n",
    "Y_test_t = torch.tensor(Y_test, dtype=torch.float32)\n",
    "\n",
    "# 拼接时间序列 + 静态特征 (最后一维)\n",
    "train_X = torch.cat([X_seq_train_t, X_static_train_t.unsqueeze(1).expand(-1, configs.seq_len, -1)], dim=-1)\n",
    "test_X = torch.cat([X_seq_test_t, X_static_test_t.unsqueeze(1).expand(-1, configs.seq_len, -1)], dim=-1)\n",
    "\n",
    "# TensorDataset + DataLoader\n",
    "BATCH_SIZE = 512\n",
    "train_dataset = TensorDataset(train_X, Y_train_t)\n",
    "val_dataset = TensorDataset(test_X, Y_test_t)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=10, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8, pin_memory=True)\n",
    "\n",
    "\n",
    "\n",
    "### 读取各个工况的测试集数据 ================================================\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# ===== 读取各工况测试集 =====\n",
    "case_dir = os.path.join(data_dir, \"test_cases\")\n",
    "test_data_per_case = {}\n",
    "\n",
    "# 找出所有 case 的 X_seq 文件\n",
    "case_files = glob.glob(os.path.join(case_dir, \"X_seq_case*.npy\"))\n",
    "\n",
    "for f in case_files:\n",
    "    # 提取工况编号\n",
    "    fname = os.path.basename(f)  # eg: X_seq_case12.npy\n",
    "    case_id = int(fname.replace(\"X_seq_case\", \"\").replace(\".npy\", \"\"))\n",
    "\n",
    "    # 对应的 X_static 和 Y 文件\n",
    "    X_seq_case = np.load(os.path.join(case_dir, f\"X_seq_case{case_id}.npy\"))\n",
    "    X_static_case = np.load(os.path.join(case_dir, f\"X_static_case{case_id}.npy\"))\n",
    "    Y_case = np.load(os.path.join(case_dir, f\"Y_case{case_id}.npy\"))\n",
    "\n",
    "    test_data_per_case[case_id] = (X_seq_case, X_static_case, Y_case)\n",
    "\n",
    "print(f\"✅ 已加载 {len(test_data_per_case)} 个工况测试集\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc11a80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8dce4a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: 安全 AMP 训练 + 评估函数\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, scaler, device):\n",
    "    model.train()\n",
    "    total_loss, total_rmse, total_mape, total_r2 = 0,0,0,0\n",
    "    n_samples = 0\n",
    "\n",
    "    for xb, yb in loader:\n",
    "        B = xb.size(0)\n",
    "        xb = xb.to(device, dtype=torch.float32)\n",
    "        yb = yb.to(device, dtype=torch.float32)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # 自动混合精度\n",
    "        with torch.amp.autocast(device_type='cuda', dtype=torch.float16):\n",
    "            out = model(xb)   # [B, 6]\n",
    "            loss = continuity_loss(out, yb, beta=0.1, device=device)\n",
    "\n",
    "        if torch.isnan(loss):\n",
    "            print(\"⚠️ Loss is NaN, skipping this batch.\")\n",
    "            continue\n",
    "\n",
    "        # 反向 + 梯度裁剪 + AMP\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)  # ✅ 解锁梯度\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # 可选，防梯度爆炸\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # CPU 指标计算\n",
    "        y_np, out_np = yb.detach().cpu().numpy(), out.detach().cpu().numpy()\n",
    "\n",
    "        if np.isnan(out_np).any() or np.isnan(y_np).any():\n",
    "            print(\"⚠️ NaN detected in out_np or y_np, skipping this batch.\")\n",
    "            continue\n",
    "        if np.isinf(out_np).any():\n",
    "            print(\"⚠️ Inf detected in out_np, clipping.\")\n",
    "            out_np = np.nan_to_num(out_np, nan=0.0, posinf=1e6, neginf=-1e6)\n",
    "\n",
    "        rmse = np.sqrt(mean_squared_error(y_np, out_np))\n",
    "        #mape = mean_absolute_percentage_error(y_np, out_np)\n",
    "        r2 = r2_score(y_np, out_np)\n",
    "\n",
    "        total_loss += loss.item() * B\n",
    "        total_rmse += rmse * B\n",
    "        #total_mape += mape * B\n",
    "        total_r2 += r2 * B\n",
    "        n_samples += B\n",
    "\n",
    "    return total_loss/n_samples, total_rmse/n_samples, 0, total_r2/n_samples\n",
    "\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    total_loss, total_rmse, total_mape, total_max, total_r2 = 0,0,0,0,0\n",
    "    n_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            B = xb.size(0)\n",
    "            xb = xb.to(device, dtype=torch.float32)\n",
    "            yb = yb.to(device, dtype=torch.float32)\n",
    "\n",
    "            out = model(xb)\n",
    "            loss = continuity_loss(out, yb, beta=0.1, device=device)\n",
    "\n",
    "            y_np, out_np = yb.detach().cpu().numpy(), out.detach().cpu().numpy()\n",
    "            rmse = np.sqrt(mean_squared_error(y_np, out_np))\n",
    "            mape = mean_absolute_percentage_error(y_np, out_np)\n",
    "            max_err = np.max(np.abs(y_np - out_np))\n",
    "            #r2 = r2_score(y_np, out_np)\n",
    "\n",
    "            total_loss += loss.item() * B\n",
    "            total_rmse += rmse * B\n",
    "            total_mape += mape * B\n",
    "            total_max += max_err * B\n",
    "            #total_r2 += r2 * B\n",
    "            n_samples += B\n",
    "\n",
    "    return total_loss/n_samples, total_rmse/n_samples, total_mape/n_samples, total_max/n_samples, 0 #total_r2/n_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8429a1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PatchTSTRegressor(\n",
      "  (tft): CompactTFT(\n",
      "    (input_proj): Linear(in_features=3, out_features=64, bias=True)\n",
      "    (pos_encoding): PositionalEncoding()\n",
      "    (encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0-1): 2 x TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.3, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.3, inplace=False)\n",
      "          (dropout2): Dropout(p=0.3, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (static_fuse): GRN(\n",
      "      (fc1): Linear(in_features=64, out_features=128, bias=True)\n",
      "      (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (gate): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.3, inplace=False)\n",
      "    )\n",
      "    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (patch_model): Model(\n",
      "    (decomp_module): series_decomp(\n",
      "      (moving_avg): moving_avg(\n",
      "        (avg): AvgPool1d(kernel_size=(25,), stride=(1,), padding=(0,))\n",
      "      )\n",
      "    )\n",
      "    (model_trend): PatchTST_backbone(\n",
      "      (revin_layer): RevIN()\n",
      "      (backbone): TSTiEncoder(\n",
      "        (W_P): Linear(in_features=16, out_features=64, bias=True)\n",
      "        (dropout): Dropout(p=0.4, inplace=False)\n",
      "        (encoder): TSTEncoder(\n",
      "          (layers): ModuleList(\n",
      "            (0-2): 3 x TSTEncoderLayer(\n",
      "              (self_attn): _MultiheadAttention(\n",
      "                (W_Q): Linear(in_features=64, out_features=64, bias=True)\n",
      "                (W_K): Linear(in_features=64, out_features=64, bias=True)\n",
      "                (W_V): Linear(in_features=64, out_features=64, bias=True)\n",
      "                (sdp_attn): _ScaledDotProductAttention(\n",
      "                  (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (to_out): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "                  (1): Dropout(p=0.4, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (dropout_attn): Dropout(p=0.4, inplace=False)\n",
      "              (norm_attn): Sequential(\n",
      "                (0): Transpose()\n",
      "                (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Transpose()\n",
      "              )\n",
      "              (ff): Sequential(\n",
      "                (0): Linear(in_features=64, out_features=128, bias=True)\n",
      "                (1): GELU(approximate='none')\n",
      "                (2): Dropout(p=0.4, inplace=False)\n",
      "                (3): Linear(in_features=128, out_features=64, bias=True)\n",
      "              )\n",
      "              (dropout_ffn): Dropout(p=0.4, inplace=False)\n",
      "              (norm_ffn): Sequential(\n",
      "                (0): Transpose()\n",
      "                (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Transpose()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (head): Flatten_Head(\n",
      "        (flatten): Flatten(start_dim=-2, end_dim=-1)\n",
      "        (linear): Linear(in_features=704, out_features=1, bias=True)\n",
      "        (dropout): Dropout(p=0.4, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (model_res): PatchTST_backbone(\n",
      "      (revin_layer): RevIN()\n",
      "      (backbone): TSTiEncoder(\n",
      "        (W_P): Linear(in_features=16, out_features=64, bias=True)\n",
      "        (dropout): Dropout(p=0.4, inplace=False)\n",
      "        (encoder): TSTEncoder(\n",
      "          (layers): ModuleList(\n",
      "            (0-2): 3 x TSTEncoderLayer(\n",
      "              (self_attn): _MultiheadAttention(\n",
      "                (W_Q): Linear(in_features=64, out_features=64, bias=True)\n",
      "                (W_K): Linear(in_features=64, out_features=64, bias=True)\n",
      "                (W_V): Linear(in_features=64, out_features=64, bias=True)\n",
      "                (sdp_attn): _ScaledDotProductAttention(\n",
      "                  (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (to_out): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "                  (1): Dropout(p=0.4, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (dropout_attn): Dropout(p=0.4, inplace=False)\n",
      "              (norm_attn): Sequential(\n",
      "                (0): Transpose()\n",
      "                (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Transpose()\n",
      "              )\n",
      "              (ff): Sequential(\n",
      "                (0): Linear(in_features=64, out_features=128, bias=True)\n",
      "                (1): GELU(approximate='none')\n",
      "                (2): Dropout(p=0.4, inplace=False)\n",
      "                (3): Linear(in_features=128, out_features=64, bias=True)\n",
      "              )\n",
      "              (dropout_ffn): Dropout(p=0.4, inplace=False)\n",
      "              (norm_ffn): Sequential(\n",
      "                (0): Transpose()\n",
      "                (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Transpose()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (head): Flatten_Head(\n",
      "        (flatten): Flatten(start_dim=-2, end_dim=-1)\n",
      "        (linear): Linear(in_features=704, out_features=1, bias=True)\n",
      "        (dropout): Dropout(p=0.4, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (graph_block): GraphResidualBlock(\n",
      "    (fc1): Linear(in_features=1, out_features=32, bias=True)\n",
      "    (fc2): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      "  (head): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=32, out_features=6, bias=True)\n",
      "  )\n",
      ")\n",
      "=============================================================================================================================\n",
      "Layer (type:depth-idx)                                                      Output Shape              Param #\n",
      "=============================================================================================================================\n",
      "PatchTSTRegressor                                                           [2, 6]                    --\n",
      "├─CompactTFT: 1-1                                                           [2, 100, 64]              20,864\n",
      "│    └─Linear: 2-1                                                          [2, 100, 64]              256\n",
      "│    └─PositionalEncoding: 2-2                                              [2, 100, 64]              --\n",
      "│    └─TransformerEncoder: 2-3                                              [2, 100, 64]              --\n",
      "│    │    └─ModuleList: 3-1                                                 --                        66,944\n",
      "│    └─LayerNorm: 2-4                                                       [2, 100, 64]              128\n",
      "├─Model: 1-2                                                                [2, 1, 64]                --\n",
      "│    └─series_decomp: 2-5                                                   [2, 100, 64]              --\n",
      "│    │    └─moving_avg: 3-2                                                 [2, 100, 64]              --\n",
      "│    └─PatchTST_backbone: 2-6                                               [2, 64, 1]                --\n",
      "│    │    └─RevIN: 3-3                                                      [2, 100, 64]              128\n",
      "│    │    └─TSTiEncoder: 3-4                                                [2, 64, 64, 11]           102,211\n",
      "│    │    └─Flatten_Head: 3-5                                               [2, 64, 1]                705\n",
      "│    │    └─RevIN: 3-6                                                      [2, 1, 64]                (recursive)\n",
      "│    └─PatchTST_backbone: 2-7                                               [2, 64, 1]                --\n",
      "│    │    └─RevIN: 3-7                                                      [2, 100, 64]              128\n",
      "│    │    └─TSTiEncoder: 3-8                                                [2, 64, 64, 11]           102,211\n",
      "│    │    └─Flatten_Head: 3-9                                               [2, 64, 1]                705\n",
      "│    │    └─RevIN: 3-10                                                     [2, 1, 64]                (recursive)\n",
      "├─Sequential: 1-3                                                           [2, 6]                    --\n",
      "│    └─Flatten: 2-8                                                         [2, 64]                   --\n",
      "│    └─Linear: 2-9                                                          [2, 32]                   2,080\n",
      "│    └─ReLU: 2-10                                                           [2, 32]                   --\n",
      "│    └─Linear: 2-11                                                         [2, 6]                    198\n",
      "├─GraphResidualBlock: 1-4                                                   [2, 6]                    36\n",
      "│    └─Linear: 2-12                                                         [2, 6, 32]                64\n",
      "│    └─Linear: 2-13                                                         [2, 6, 1]                 33\n",
      "=============================================================================================================================\n",
      "Total params: 296,691\n",
      "Trainable params: 296,685\n",
      "Non-trainable params: 6\n",
      "Total mult-adds (Units.MEGABYTES): 25.84\n",
      "=============================================================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 41.81\n",
      "Params size (MB): 0.96\n",
      "Estimated Total Size (MB): 42.78\n",
      "=============================================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=============================================================================================================================\n",
       "Layer (type:depth-idx)                                                      Output Shape              Param #\n",
       "=============================================================================================================================\n",
       "PatchTSTRegressor                                                           [2, 6]                    --\n",
       "├─CompactTFT: 1-1                                                           [2, 100, 64]              20,864\n",
       "│    └─Linear: 2-1                                                          [2, 100, 64]              256\n",
       "│    └─PositionalEncoding: 2-2                                              [2, 100, 64]              --\n",
       "│    └─TransformerEncoder: 2-3                                              [2, 100, 64]              --\n",
       "│    │    └─ModuleList: 3-1                                                 --                        66,944\n",
       "│    └─LayerNorm: 2-4                                                       [2, 100, 64]              128\n",
       "├─Model: 1-2                                                                [2, 1, 64]                --\n",
       "│    └─series_decomp: 2-5                                                   [2, 100, 64]              --\n",
       "│    │    └─moving_avg: 3-2                                                 [2, 100, 64]              --\n",
       "│    └─PatchTST_backbone: 2-6                                               [2, 64, 1]                --\n",
       "│    │    └─RevIN: 3-3                                                      [2, 100, 64]              128\n",
       "│    │    └─TSTiEncoder: 3-4                                                [2, 64, 64, 11]           102,211\n",
       "│    │    └─Flatten_Head: 3-5                                               [2, 64, 1]                705\n",
       "│    │    └─RevIN: 3-6                                                      [2, 1, 64]                (recursive)\n",
       "│    └─PatchTST_backbone: 2-7                                               [2, 64, 1]                --\n",
       "│    │    └─RevIN: 3-7                                                      [2, 100, 64]              128\n",
       "│    │    └─TSTiEncoder: 3-8                                                [2, 64, 64, 11]           102,211\n",
       "│    │    └─Flatten_Head: 3-9                                               [2, 64, 1]                705\n",
       "│    │    └─RevIN: 3-10                                                     [2, 1, 64]                (recursive)\n",
       "├─Sequential: 1-3                                                           [2, 6]                    --\n",
       "│    └─Flatten: 2-8                                                         [2, 64]                   --\n",
       "│    └─Linear: 2-9                                                          [2, 32]                   2,080\n",
       "│    └─ReLU: 2-10                                                           [2, 32]                   --\n",
       "│    └─Linear: 2-11                                                         [2, 6]                    198\n",
       "├─GraphResidualBlock: 1-4                                                   [2, 6]                    36\n",
       "│    └─Linear: 2-12                                                         [2, 6, 32]                64\n",
       "│    └─Linear: 2-13                                                         [2, 6, 1]                 33\n",
       "=============================================================================================================================\n",
       "Total params: 296,691\n",
       "Trainable params: 296,685\n",
       "Non-trainable params: 6\n",
       "Total mult-adds (Units.MEGABYTES): 25.84\n",
       "=============================================================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 41.81\n",
       "Params size (MB): 0.96\n",
       "Estimated Total Size (MB): 42.78\n",
       "============================================================================================================================="
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model)\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "summary(\n",
    "    model,\n",
    "    input_data=torch.randn(2, configs.seq_len, configs.enc_in).to(device),  # 对应 PatchTSTRegressor.forward\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272915af",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5000\n",
    "best_val_loss = float('inf')\n",
    "best_val_me = float(\"inf\")\n",
    "\n",
    "train_loss_list, val_loss_list = [], []\n",
    "\n",
    "save_path = r\"D:\\0DATA\\TFT_PatchTST_GR\"\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "excel_file = os.path.join(save_path, \"train_val_loss_1008.xlsx\")\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
    "scaler = torch.amp.GradScaler()\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    train_loss, train_rmse, train_mape, train_r2 = train_one_epoch(model, train_loader, optimizer, scaler, device)\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    val_loss, val_rmse, val_mape, val_max, val_r2 = evaluate(model, val_loader, device)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model, os.path.join(save_path, f\"best_val_mse_1013_test.pth\"))\n",
    "\n",
    "    if val_max < best_val_me:\n",
    "        best_val_me = val_max\n",
    "        torch.save(model, os.path.join(save_path, f\"best_val_max_1013_test.pth\"))\n",
    "\n",
    "\n",
    "    # --- 输出指标 ---\n",
    "    print(\n",
    "        f\"Epoch {epoch:02d}/{epochs} | \"\n",
    "        f\"Train Loss: {train_loss:.6f} , Val Loss: {val_loss:.6f} | \"\n",
    "        f\"Train RMSE: {train_rmse:.6f} , Train R2: {train_r2:.6f} | \"\n",
    "        f\"Val RMSE: {val_rmse:.6f} , Val MAPE: {val_mape:.6f} , Val Max_Err: {val_max:.6f}\"\n",
    "    )\n",
    "\n",
    "    # ===== 记录 loss =====\n",
    "    train_loss_list.append(train_loss)\n",
    "    val_loss_list.append(val_loss)\n",
    "\n",
    "# ===== 保存到 Excel =====\n",
    "df_loss = pd.DataFrame({\n",
    "    \"Train Loss\": train_loss_list,\n",
    "    \"Validation Loss\": val_loss_list\n",
    "})\n",
    "df_loss.to_excel(excel_file, index_label=\"Epoch\")\n",
    "\n",
    "print(\"✅ 训练完成，最佳验证集 Loss:\", best_val_loss)\n",
    "print(f\"训练/验证 Loss 已保存至: {excel_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201684bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6986444f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6462fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83de902a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01b794f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a9b6ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153bdd14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4deb037b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc88d15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30880c43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4f415b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fa3325",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35313cc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211dcc8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd6a580",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
